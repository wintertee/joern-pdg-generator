import argparse
import glob
import multiprocessing
import os
import subprocess

from tqdm import tqdm

# --- é…ç½® ---
# è¦å¤„ç†çš„è¯­è¨€
LANG = "cpp"
# æ•°æ®é›†çš„åŸºç¡€ç›®å½•è·¯å¾„
BASE_DATA_PATH = "./data/Project_CodeNet_C++1000"
# ç”¨äºæŸ¥æ‰¾æºæ–‡ä»¶çš„ Glob æ¨¡å¼ (åŸå§‹ bash è„šæœ¬ä¸º: $path/*/*.$lang)
# ä¿®æ”¹åï¼šè¿™æ„å‘³ç€åœ¨ BASE_DATA_PATH ä¸‹æœ‰ä¸€çº§å­ç›®å½•åŒ…å«æºæ–‡ä»¶ã€‚
FILE_GLOB_PATTERN = os.path.join(BASE_DATA_PATH, "*", f"*.{LANG}")
# CPG-neo4j å¯æ‰§è¡Œæ–‡ä»¶çš„ç»å¯¹è·¯å¾„
CPG_NEO4J_EXECUTABLE = "../cpg/cpg-neo4j/build/install/cpg-neo4j/bin/cpg-neo4j"
# json2dot.py è„šæœ¬çš„ç»å¯¹è·¯å¾„
JSON2DOT_SCRIPT = os.path.abspath("./src/json2dot.py")
# --- é…ç½®ç»“æŸ ---


def process_file(args):
    """
    ä½¿ç”¨ CPG-neo4j å’Œ json2dot.py è„šæœ¬å¤„ç†å•ä¸ªæºä»£ç æ–‡ä»¶ã€‚
    æ¯ä¸ªæ–‡ä»¶çš„è¾“å‡ºéƒ½å­˜å‚¨åœ¨ä»¥è¾“å…¥æ–‡ä»¶å‘½åçš„ç›®å½•å†…çš„ 'cpg' å­ç›®å½•ä¸­ï¼Œ
    è¯¥ç›®å½•ä¸è¾“å…¥æ–‡ä»¶ä½äºåŒä¸€ç›®å½•ã€‚
    ä¾‹å¦‚ï¼šè¾“å…¥: path/to/file.cpp -> è¾“å‡º: path/to/file/cpg/
    è¿”å›: (file_path, success_boolean, message_string)
    """
    file_path, lang_param = args
    abs_file_path = os.path.abspath(file_path)
    current_file_cpg_root = ""  # ä¸ºæ¸…æ™°èµ·è§ï¼Œåœ¨æ—©æœŸé”™è¯¯å‘ç”Ÿæ—¶åˆå§‹åŒ–

    try:
        # 1. ç¡®å®šå¹¶ä¸ºæ­¤æ–‡ä»¶åˆ›å»ºå”¯ä¸€çš„è¾“å‡ºç›®å½•ã€‚
        input_file_parent_dir = os.path.dirname(abs_file_path)
        input_filename_no_ext = os.path.splitext(os.path.basename(abs_file_path))[0]
        per_file_base_dir = os.path.join(input_file_parent_dir, input_filename_no_ext)
        current_file_cpg_root = os.path.join(per_file_base_dir, "cpg")
        os.makedirs(current_file_cpg_root, exist_ok=True)

        # 2. è¿è¡Œ cpg-neo4j ç”Ÿæˆ JSON æ–‡ä»¶
        cpg_json_output = os.path.join(current_file_cpg_root, "cpg-export.json")
        cpg_cmd = [CPG_NEO4J_EXECUTABLE, "--export-json", cpg_json_output, "--no-neo4j", abs_file_path]
        cpg_result = subprocess.run(
            cpg_cmd,
            cwd=current_file_cpg_root,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=False,
        )
        if cpg_result.returncode != 0:
            print(f"\n[ERROR] cpg-neo4j æ‰§è¡Œå¤±è´¥: {' '.join(cpg_cmd)}")
            print(f"[STDOUT]:\n{cpg_result.stdout}")
            print(f"[STDERR]:\n{cpg_result.stderr}")
            raise subprocess.CalledProcessError(
                returncode=cpg_result.returncode,
                cmd=cpg_cmd,
                stderr=cpg_result.stderr,
                output=cpg_result.stdout,
            )

        # 3. è¿è¡Œ json2dot.py ç”Ÿæˆ DOT æ–‡ä»¶
        json2dot_cmd = ["uv", "run", JSON2DOT_SCRIPT, cpg_json_output, "-o", current_file_cpg_root]
        json2dot_result = subprocess.run(
            json2dot_cmd,
            cwd=current_file_cpg_root,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=False,
        )
        if json2dot_result.returncode != 0:
            print(f"\n[ERROR] json2dot.py æ‰§è¡Œå¤±è´¥: {' '.join(json2dot_cmd)}")
            print(f"[STDOUT]:\n{json2dot_result.stdout}")
            print(f"[STDERR]:\n{json2dot_result.stderr}")
            raise subprocess.CalledProcessError(
                returncode=json2dot_result.returncode,
                cmd=json2dot_cmd,
                stderr=json2dot_result.stderr,
                output=json2dot_result.stdout,
            )

        return (file_path, True, f"è¾“å‡ºä½äº {current_file_cpg_root}")

    except subprocess.CalledProcessError as e:
        error_details = f"å‘½ä»¤ '{' '.join(e.cmd)}' æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºä»£ç  {e.returncode}ã€‚"
        if hasattr(e, "output") and e.output and e.output.strip():
            error_details += f"\næ ‡å‡†è¾“å‡º:\n{e.output.strip()}"
        if e.stderr and e.stderr.strip():
            error_details += f"\næ ‡å‡†é”™è¯¯:\n{e.stderr.strip()}"
        return (file_path, False, error_details)
    except FileNotFoundError as e:
        return (file_path, False, f"æœªæ‰¾åˆ°æ‰€éœ€çš„æ–‡ä»¶æˆ–ç›®å½• - {e}")
    except Exception as e:
        return (file_path, False, f"å‘ç”Ÿæ„å¤–é”™è¯¯ - {type(e).__name__}: {e}")


def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºå‘ç°æ–‡ä»¶å¹¶å¹¶è¡Œå¤„ç†å®ƒä»¬ã€‚
    å¤„ç† KeyboardInterrupt ä»¥å®ç°ä¼˜é›…å…³é—­ã€‚
    """
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ CPG-neo4j å’Œ json2dot.py å¹¶è¡Œå¤„ç†æºæ–‡ä»¶")
    parser.add_argument(
        "--num_workers",
        type=int,
        default=multiprocessing.cpu_count(),
        help="å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œé»˜è®¤ç­‰äºCPUæ ¸å¿ƒæ•°",
    )
    parser.add_argument(
        "--file_list",
        type=str,
        help="åŒ…å«è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨çš„æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœæä¾›ï¼Œåˆ™ä»æ­¤æ–‡ä»¶è¯»å–æ–‡ä»¶åˆ—è¡¨è€Œä¸ä½¿ç”¨globæ¨¡å¼æœç´¢",
    )
    args = parser.parse_args()

    print("--------------------------------------------------------------------------")
    print("ğŸ ä½¿ç”¨ CPG-neo4j å’Œ json2dot.py å¤„ç†æºæ–‡ä»¶çš„ Python è„šæœ¬")
    print("   (è¾“å‡ºåˆ°æ¯ä¸ªæ–‡ä»¶çš„ '<æ–‡ä»¶å>/cpg/' å­ç›®å½•)")
    print("--------------------------------------------------------------------------")
    print("ğŸ“‹ å…ˆå†³æ¡ä»¶:")
    print("  1. CPG-neo4j å¿…é¡»å·²å®‰è£…å¹¶å¯æ‰§è¡Œã€‚")
    if not args.file_list:
        print(f"  2. æ•°æ®é›† (ä¾‹å¦‚ Project_CodeNet_C++1000) å¿…é¡»ä½äº: {os.path.abspath(BASE_DATA_PATH)}")
    print(f"  {'3' if not args.file_list else '2'}. json2dot.py è„šæœ¬å¿…é¡»å­˜åœ¨äº: {JSON2DOT_SCRIPT}")
    if args.file_list:
        print("  3. æ–‡ä»¶åˆ—è¡¨æ ¼å¼: æ¯è¡Œä¸€ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒ # å¼€å¤´çš„æ³¨é‡Šè¡Œ")
    print("éšæ—¶æŒ‰ Ctrl+C ä¸­æ–­å¤„ç†ã€‚")
    print("--------------------------------------------------------------------------\n")

    if not os.path.exists(JSON2DOT_SCRIPT):
        print(f"ğŸ”´ ä¸¥é‡é”™è¯¯: æœªæ‰¾åˆ° json2dot.py è„šæœ¬ {JSON2DOT_SCRIPT}ã€‚æ­£åœ¨é€€å‡ºã€‚")
        return

    if not os.path.exists(CPG_NEO4J_EXECUTABLE):
        print(f"ğŸ”´ ä¸¥é‡é”™è¯¯: æœªæ‰¾åˆ° CPG-neo4j å¯æ‰§è¡Œæ–‡ä»¶ {CPG_NEO4J_EXECUTABLE}ã€‚æ­£åœ¨é€€å‡ºã€‚")
        return

    # æ ¹æ®æ˜¯å¦æä¾›æ–‡ä»¶åˆ—è¡¨é€‰æ‹©ä¸åŒçš„æ–‡ä»¶å‘ç°æ–¹å¼
    if args.file_list:
        # ä»æ–‡ä»¶åˆ—è¡¨è¯»å–æ–‡ä»¶
        if not os.path.exists(args.file_list):
            print(f"ğŸ”´ ä¸¥é‡é”™è¯¯: æŒ‡å®šçš„æ–‡ä»¶åˆ—è¡¨ {args.file_list} ä¸å­˜åœ¨ã€‚æ­£åœ¨é€€å‡ºã€‚")
            return

        print(f"ğŸ“‚ ä»æ–‡ä»¶åˆ—è¡¨è¯»å–è¦å¤„ç†çš„æ–‡ä»¶: {args.file_list}...")
        files_to_process = []
        try:
            with open(args.file_list, "r", encoding="utf-8") as f:
                for line in f:
                    file_path = line.strip()
                    if file_path and not file_path.startswith("#"):  # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                        if os.path.exists(file_path):
                            files_to_process.append(file_path)
                        else:
                            print(f"âš ï¸ è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
        except Exception as e:
            print(f"ğŸ”´ ä¸¥é‡é”™è¯¯: æ— æ³•è¯»å–æ–‡ä»¶åˆ—è¡¨ {args.file_list}: {e}")
            return

        files_to_process = sorted(files_to_process)
        print(f"ğŸ“‹ ä»æ–‡ä»¶åˆ—è¡¨ä¸­è¯»å–åˆ° {len(files_to_process)} ä¸ªæœ‰æ•ˆæ–‡ä»¶ã€‚")
    else:
        # ä½¿ç”¨åŸæœ‰çš„globæ¨¡å¼æœç´¢
        if not os.path.isdir(BASE_DATA_PATH):
            print(f"ğŸ”´ ä¸¥é‡é”™è¯¯: åŸºç¡€æ•°æ®è·¯å¾„ {os.path.abspath(BASE_DATA_PATH)} ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•ã€‚æ­£åœ¨é€€å‡ºã€‚")
            return

        print(f"ğŸ” æ­£åœ¨ä½¿ç”¨æ¨¡å¼æœç´¢ '{LANG}' æ–‡ä»¶: {FILE_GLOB_PATTERN}...")
        # æŒ‰æ–‡ä»¶åæ’åºæ–‡ä»¶åˆ—è¡¨
        files_to_process = sorted(glob.glob(FILE_GLOB_PATTERN))

    # æ–­ç‚¹ç»­è·‘æ•°æ®åº“æ–‡ä»¶
    PROCESSED_DB_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "processed_files.txt")
    FAILED_DB_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "failed_files.txt")
    processed_files_set = set()
    if os.path.exists(PROCESSED_DB_PATH):
        with open(PROCESSED_DB_PATH, "r", encoding="utf-8") as f:
            for line in f:
                processed_files_set.add(line.strip())

    # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ–‡ä»¶
    original_count = len(files_to_process)
    files_to_process = [fp for fp in files_to_process if os.path.abspath(fp) not in processed_files_set]
    filtered_count = original_count - len(files_to_process)

    if not files_to_process:
        if args.file_list:
            print("æ–‡ä»¶åˆ—è¡¨ä¸­çš„æ‰€æœ‰æ–‡ä»¶å‡å·²å¤„ç†ï¼Œæ— éœ€é‡å¤å¤„ç†ã€‚")
        else:
            print("æ‰€æœ‰æ–‡ä»¶å‡å·²å¤„ç†ï¼Œæ— éœ€é‡å¤å¤„ç†ã€‚")
        return

    if args.file_list:
        print(f"âœ… æ–‡ä»¶åˆ—è¡¨ä¸­æœ‰ {len(files_to_process)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
        if filtered_count > 0:
            print(f"   (å·²è·³è¿‡ {filtered_count} ä¸ªå·²å¤„ç†çš„æ–‡ä»¶)")
    else:
        print(f"âœ… æ‰¾åˆ° {len(files_to_process)} ä¸ªè¦å¤„ç†çš„æ–‡ä»¶ (å·²æŒ‰æ–‡ä»¶åæ’åºï¼Œå·²è·³è¿‡å·²å¤„ç†æ–‡ä»¶)ã€‚")
    print("â„¹ï¸  æ¯ä¸ªæ–‡ä»¶ 'path/to/file.ext' çš„è¾“å‡ºå°†ä½äº 'path/to/file/cpg/'ã€‚")

    tasks_args = [
        (
            fp,
            LANG,
        )
        for fp in files_to_process
    ]
    num_workers = args.num_workers
    # num_workers = max(1, min(cpu_cores // 2, 16))
    # num_workers = 1 # ç”¨äºè°ƒè¯•

    results_log = []  # å­˜å‚¨ (file_path, success_bool, message_str) å…ƒç»„
    success_count = 0
    error_count = 0
    print(f"âš™ï¸  æ­£åœ¨ä½¿ç”¨ {num_workers} ä¸ªå·¥ä½œè¿›ç¨‹åˆå§‹åŒ–å¹¶è¡Œå¤„ç†...")

    try:
        with multiprocessing.Pool(processes=num_workers) as pool:
            with tqdm(total=len(tasks_args), desc="ğŸš€ å¤„ç†æ–‡ä»¶", smoothing=0) as pbar:
                for result_tuple in pool.imap_unordered(process_file, tasks_args):
                    results_log.append(result_tuple)
                    if result_tuple[1]:
                        success_count += 1
                    else:
                        error_count += 1
                    pbar.set_postfix({"æˆåŠŸ": success_count, "å¤±è´¥": error_count})
                    pbar.update(1)

                    # Panic exit if error rate > 50% and processed > 10
                    total_processed = success_count + error_count
                    if total_processed > 10 and error_count / total_processed > 0.5:
                        print(
                            "\nğŸ›‘ Panic exit: é”™è¯¯ç‡è¶…è¿‡50%ï¼Œå·²å¤„ç†æ–‡ä»¶æ•°ï¼š{}ï¼Œå¤±è´¥æ•°ï¼š{}".format(
                                total_processed, error_count
                            )
                        )
                        pool.terminate()
                        pool.join()
                        raise SystemExit("Panic exit due to high error rate.")
    except KeyboardInterrupt:
        print("\nğŸš« ç”¨æˆ·é€šè¿‡ (Ctrl+C) ä¸­æ–­äº†è¿›ç¨‹ã€‚å·¥ä½œè¿›ç¨‹æ­£åœ¨ç»ˆæ­¢ã€‚")
        print("   å°†æ˜¾ç¤ºå·²å®Œæˆå·¥ä½œçš„æ‘˜è¦ã€‚")
    except Exception as e:
        print(f"\nâŒ å¹¶è¡Œå¤„ç†æœŸé—´å‘ç”Ÿæ„å¤–é”™è¯¯: {type(e).__name__} - {e}")
        print("   å·¥ä½œè¿›ç¨‹æ­£åœ¨ç»ˆæ­¢ã€‚å°†æ˜¾ç¤ºå·²å®Œæˆå·¥ä½œçš„æ‘˜è¦ã€‚")
    finally:
        # ç»Ÿä¸€å†™å…¥æœ¬è½®æ–°æˆåŠŸçš„æ–‡ä»¶åˆ° processed_files.txt
        new_success_files = [os.path.abspath(fp) for fp, success, _ in results_log if success]
        if new_success_files:
            with open(PROCESSED_DB_PATH, "a", encoding="utf-8") as f:
                for fp in new_success_files:
                    f.write(fp + "\n")

        # ç»Ÿä¸€å†™å…¥æœ¬è½®æ–°å¤±è´¥çš„æ–‡ä»¶åˆ° failed_files.txt
        new_failed_files = [os.path.abspath(fp) for fp, success, _ in results_log if not success]
        if new_failed_files:
            with open(FAILED_DB_PATH, "a", encoding="utf-8") as f:
                for fp in new_failed_files:
                    f.write(fp + "\n")

        print("\n--- ğŸ“Š å¤„ç†æ‘˜è¦ ---")

        # æ ¹æ®åŸå§‹æ–‡ä»¶åå¯¹ç»“æœè¿›è¡Œæ’åº
        results_log.sort(key=lambda item: item[0])

        success_count = 0
        error_count = 0

        if not results_log and files_to_process:
            print("æ²¡æœ‰ä»»åŠ¡å®Œæˆæˆ–è®°å½•ç»“æœï¼Œå¯èƒ½æ˜¯ç”±äºæ—©æœŸä¸­æ–­æˆ–é”™è¯¯ã€‚")

        for original_fp, success, msg_detail in results_log:
            if success:
                success_count += 1
                # å¯ä»¥é€‰æ‹©åœ¨è¿™é‡Œæ‰“å°æ¯ä¸ªæˆåŠŸçš„æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¦‚æœéœ€è¦çš„è¯
                # print(f"æˆåŠŸ: {original_fp} å·²å¤„ç†ã€‚{msg_detail}")
            else:
                error_count += 1
                print(f"å¤„ç† {original_fp} æ—¶å‡ºé”™: {msg_detail}")  # æ‰“å°å¤±è´¥æ–‡ä»¶çš„å®Œæ•´é”™è¯¯æ¶ˆæ¯

        total_attempted_or_logged = len(results_log)
        print(f"\nå¤„ç†/å°è¯•çš„ä»»åŠ¡æ•°ï¼ˆæˆªè‡³ä¸­æ–­/å®Œæˆï¼‰: {total_attempted_or_logged} / {len(files_to_process)}")
        print(f"æˆåŠŸå¤„ç†: {success_count}")
        print(f"å¤±è´¥æˆ–å‡ºé”™: {error_count}")

        if error_count > 0:
            print("âš ï¸ è¯·æŸ¥çœ‹ä¸Šé¢çš„é”™è¯¯æ¶ˆæ¯ä»¥è·å–æœ‰å…³å¤±è´¥æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯ã€‚")
        elif success_count > 0 and total_attempted_or_logged == len(files_to_process) and error_count == 0:
            print("âœ… æ‰€æœ‰æ–‡ä»¶å‡å·²æˆåŠŸå¤„ç†ï¼")
        elif success_count > 0:
            print("âœ… éƒ¨åˆ†æ–‡ä»¶å·²æˆåŠŸå¤„ç†ã€‚")
        elif total_attempted_or_logged == 0 and len(files_to_process) > 0:
            print("â„¹ï¸ æ²¡æœ‰æ–‡ä»¶è¢«å¤„ç†ï¼ˆå¯èƒ½æ˜¯åœ¨å¤„ç†å¼€å§‹å‰ç«‹å³ä¸­æ–­æˆ–è®¾ç½®é—®é¢˜ï¼‰ã€‚")
        else:
            print("â„¹ï¸ å¤„ç†è¿è¡Œå®Œæˆã€‚")

        print(f"ğŸ”— å·²å¤„ç†çš„æ–‡ä»¶è®°å½•ä¿å­˜åœ¨: {PROCESSED_DB_PATH}")
        if new_failed_files:
            print(f"âŒ å¤±è´¥çš„æ–‡ä»¶è®°å½•ä¿å­˜åœ¨: {FAILED_DB_PATH}")


if __name__ == "__main__":
    main()
